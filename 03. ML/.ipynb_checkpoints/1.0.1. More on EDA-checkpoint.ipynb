{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0\"></a>\n",
    "\n",
    "# More on EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.1\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to Pandas Profiling](#1)\n",
    "1. [Import libraries](#2)\n",
    "1. [Import datasets](#3)\n",
    "1. [EDA with Pandas Profiling](#4)\n",
    "    -  [EDA of training set](#4.1)\n",
    "    -  [EDA of test set](#4.2)\n",
    "    -  [EDA of gender submission file](#4.3)\n",
    "1. [Conclusion](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Pandas Profiling <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "[Back to Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do after importing a dataset is to get an insight about the dataset. This is called exploratory data analysis or EDA in short. We use Pandas for EDA purposes.\n",
    "\n",
    "\n",
    "Pandas is the most widely used Python library which is used to get insights about the data. It is used for loading and processing data in Python. It has great set of tools to perform various statistical operations on the data. I have listed below some basic and common commands along with their description which are used to get insights about the data.\n",
    "\n",
    "- **head() method** - view the top 5 rows of the dataset.\n",
    "\n",
    "- **tail() method** - view the bottom 5 rows of the dataset.\n",
    "\n",
    "- **info() method** - view concise summary of dataset.\n",
    "\n",
    "- **describe() method** - view statistical properties of dataset.\n",
    "\n",
    "\n",
    "There are some basic dataframe attributes which are as follows -\n",
    "\n",
    "\n",
    "- **df.shape** - gives the dimensions of the dataset.\n",
    "\n",
    "- **df.dtypes** - gives the data types of the columns.\n",
    "\n",
    "- **df.columns** - view the column names of the dataset.\n",
    "\n",
    "\n",
    "But these methods and attributes are very basic for EDA purposes.\n",
    "\n",
    "\n",
    "There is an alternative, called **Pandas profiling**. This library generates a complete report for your dataset, which includes:\n",
    "\n",
    "- Basic data type information (which columns contain what).\n",
    "\n",
    "- Descriptive statistics (mean, average, etc.)\n",
    "\n",
    "- Quantile statistics (tells you about how your data is distributed)\n",
    "\n",
    "- Histograms for your data (again, for visualizing distributions)\n",
    "\n",
    "- Correlations (Let's you see what's related)\n",
    "\n",
    "\n",
    "This tool outputs a bunch of HTML file, containing all the information mentioned above. Instead of just giving us a single output, pandas-profiling tool provides a broadly structured HTML file containing all the relevant information that a typical EDA of all the basic commands and attributes provide. So, it saves a lot of time. Now we can perform EDA with just one line of code (as explained below).\n",
    "\n",
    "\n",
    "This Pandas Profiling tool can be download here: -\n",
    "\n",
    "https://github.com/pandas-profiling/pandas-profiling\n",
    "\n",
    "\n",
    "We will apply pandas-profiling to the Titanic data set because it has variety of data types and it contains missing values. This tool is particularly useful when the dataset is not cleaned and it requires individual exploration of the variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "[Back to Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import datasets <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "[Back to Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "\n",
    "df_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "\n",
    "df_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EDA with Pandas Profiling <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "[Back to Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "- Now, let's take a look at Pandas Profiling in action.\n",
    "\n",
    "- We will begin by first importing the `pandas_profiling` module as follows :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 EDA of training set <a class=\"anchor\" id=\"4.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.ProfileReport(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 EDA of test set <a class=\"anchor\" id=\"4.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.ProfileReport(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 EDA of `gender_submission` file <a class=\"anchor\" id=\"4.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.ProfileReport(df_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "[Back to Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "- We can see that `Pandas Profiling` is a nice tool which summarizes the dataset information in a concise way.\n",
    "\n",
    "- It generates a nice html file which gives us the `overview` of `variables` alongwith their `coorelations` and `missing values` and `sample`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Top](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
